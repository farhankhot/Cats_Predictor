{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats_Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nhJcrtXbRfjJgNvgghWke0aNV76AMa6W",
      "authorship_tag": "ABX9TyOlV5nTV7eDylVztUI/q+Tl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhankhot/Cats_Predictor/blob/main/Cats_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waV7hddcvuWN",
        "outputId": "a73f94c6-1f5a-4fab-ee89-7c52558f243e"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ydm8uk84VD2",
        "outputId": "b704be09-7355-4d88-f69e-39e62388bd35"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPZ4lWGR2hPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97732e2-f445-48cc-8d9b-ab92b495dc7a"
      },
      "source": [
        "# Write file to hosted runtime in Colab  https://stackoverflow.com/questions/21034373/how-to-load-edit-run-save-text-files-py-into-an-ipython-notebook-cell\n",
        "\n",
        "%%writefile model.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# MAKE PRODUCTION READY\n",
        "# Connect Colab with gdrive: https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/\n",
        "data_dir = '/content/gdrive/MyDrive/Cats/photos'\n",
        "\n",
        "# Connect photos to code by path https://stackoverflow.com/questions/57443122/how-to-load-images-in-google-colab-notebook-using-tensorflow-from-mounted-google\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "# TRY CODE\n",
        "# roses = list(data_dir.glob('roses/*'))\n",
        "# PIL.Image.open(str(roses[0]))\n",
        "\n",
        "# ----------DEFINE PARAMETERS FOR THE LOADER--------\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "# ---------SPLITTING TRAINING AND TEST DATA---------\n",
        "\n",
        "# DEF: image_dataset_from_directory: Generates a tf.data.Dataset from image files in a directory.\n",
        "\n",
        "# tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#     directory, labels='inferred', label_mode='int',\n",
        "#     class_names=None, color_mode='rgb', batch_size=32, image_size=(256,\n",
        "#     256), shuffle=True, seed=None, validation_split=None, subset=None,\n",
        "#     interpolation='bilinear', follow_links=False, smart_resize=False\n",
        "# )\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "def get_class_names():\n",
        "  class_names = train_ds.class_names\n",
        "  return class_names\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # ---------------DISPLAYING FIRST 9 IMAGES-------------\n",
        "  # plt.figure(figsize=(10,10))\n",
        "  # for images, labels in train_ds.take(1):\n",
        "  #   for i in range(9):\n",
        "  #     ax = plt.subplot(3, 3, i+1)\n",
        "  #     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "  #     plt.title(class_names[labels[i]])\n",
        "  #     plt.axis(\"off\")\n",
        "\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "  train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "  val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "  # ----------STANDARDIZE VALUES FROM [0,255] to [0, 1]------------\n",
        "  normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "  # -------------OVERFITTING FIX------------\n",
        "  # DATA AUGMENTATION: Data augmentation takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. \n",
        "  #                    This helps expose the model to more aspects of the data and generalize better.\n",
        "  # DROPOUt is also employed\n",
        "  data_augmentation = keras.Sequential([\n",
        "                                        layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape = (img_height, img_width, 3) ),\n",
        "                                        layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "                                        layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ])\n",
        "\n",
        "\n",
        "  # -----------CREATE MODEL---------------\n",
        "  num_classes = 12 \n",
        "  model = Sequential ([\n",
        "    data_augmentation,\n",
        "    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'), # Layer 1\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'), # Layer 2\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'), # Layer 3\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "  ])\n",
        "\n",
        "  # -------------COMPILE MODEL------------\n",
        "  model.compile(optimizer = 'adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # -------------TRAIN MODEL--------------\n",
        "  epochs = 10\n",
        "  history = model.fit(train_ds, validation_data = val_ds, epochs=epochs)\n",
        "\n",
        "  # Save model to drive: https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model\n",
        "  model.save('/content/gdrive/MyDrive/Cats/model/my_model.h5')\n",
        "\n",
        "  # View the model\n",
        "  # new_model.summary()\n",
        "\n",
        "  # --------------CHECKING MODEL STATS------------\n",
        "  # acc = history.history['accuracy']\n",
        "  # val_acc = history.history['val_accuracy']\n",
        "\n",
        "  # loss = history.history['loss']\n",
        "  # val_loss = history.history['val_loss']\n",
        "\n",
        "  # epochs_range = range(epochs)\n",
        "\n",
        "  # plt.figure(figsize=(8, 8))\n",
        "  # plt.subplot(1, 2, 1)\n",
        "  # plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  # plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  # plt.legend(loc='lower right')\n",
        "  # plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  # plt.subplot(1, 2, 2)\n",
        "  # plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  # plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  # plt.legend(loc='upper right')\n",
        "  # plt.title('Training and Validation Loss')\n",
        "  # plt.show()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybCP1Q7OwgUg"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# FLask on Google Colab: https://medium.com/@kshitijvijay271199/flask-on-google-colab-f6525986797b\n",
        "\n",
        "# BAD IMPORT, CHANGE TO PRODUCTION LOCATION\n",
        "# Import only the function (still causes model.py to run): https://stackoverflow.com/questions/6523791/why-is-python-running-my-module-when-i-import-it-and-how-do-i-stop-it\n",
        "from model import get_class_names\n",
        "\n",
        "# To add flask_ngrok: https://colab.research.google.com/notebooks/snippets/importing_libraries.ipynb\n",
        "\n",
        "# Running flask in repl.it: https://stackoverflow.com/questions/30554702/cant-connect-to-flask-web-service-connection-refused\n",
        "app = Flask(__name__, static_folder='/content/gdrive/MyDrive/Cats/static')\n",
        "\n",
        "# Use app.config to specify upload folder: https://flask.palletsprojects.com/en/2.0.x/patterns/fileuploads/ \n",
        "app.config['UPLOAD_FOLDER'] = '/content/gdrive/MyDrive/Cats/user_inputs'\n",
        "run_with_ngrok(app)\n",
        "\n",
        "def predict(image):\n",
        "\n",
        "  # https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model\n",
        "  new_model = tf.keras.models.load_model('/content/gdrive/MyDrive/Cats/model/my_model.h5', custom_objects={'tf': tf})\n",
        "\n",
        "  # ----------------CHECK WITH SAMPLE IMAGE------------------\n",
        "\n",
        "  # cat_path = '/content/gdrive/MyDrive/photos/samples/sample_cat_3.jpg'\n",
        "  # cat_path = pathlib.Path(cat_path)\n",
        "\n",
        "  cat_path = image\n",
        "\n",
        "  img = keras.preprocessing.image.load_img(cat_path, target_size=(180, 180) ) # Change to img_height, img_width someday\n",
        "\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array,0)\n",
        "\n",
        "  predictions = new_model.predict(img_array)\n",
        "  score = tf.nn.softmax(predictions[0]) # get first prediction\n",
        "  class_names = get_class_names()\n",
        "  np.argmax(score)\n",
        "\n",
        "  # Formatting: https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python\n",
        "  print(\"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(class_names[np.argmax(score)], 100 * np.max(score)))\n",
        "  \n",
        "  ans = class_names[np.argmax(score)]\n",
        "  \n",
        "  return ans, 100 * np.max(score)\n",
        "\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def home():\n",
        "\n",
        "  # POST and GET in same route: https://stackoverflow.com/questions/42018603/handling-get-and-post-in-same-flask-view\n",
        "\n",
        "  if request.method == 'POST':\n",
        "    data = request.files['postPicture']\n",
        "    \n",
        "    # Save to Google Drive: https://stackoverflow.com/questions/42424853/saving-upload-in-flask-only-saves-to-project-root\n",
        "    data.save(os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(data.filename))) # WTF \n",
        "    # print(data.read)\n",
        "\n",
        "    # Formatting: https://stackoverflow.com/questions/17153779/how-can-i-print-variable-and-string-on-same-line-in-python\n",
        "    x = '/content/gdrive/MyDrive/Cats/user_inputs/{}'.format(data.filename) \n",
        "    \n",
        "    name, confidence = predict(x)  \n",
        "    \n",
        "    return \"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(name, confidence)\n",
        "  else:\n",
        "\t  return app.send_static_file('page.html')\n",
        "\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}